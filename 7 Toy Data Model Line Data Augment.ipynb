{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.transform import rotate\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import imageio\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "import matplotlib.patches as patches\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 25\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 50, 50\n",
    "\n",
    "\n",
    "def rotation(img, n):\n",
    "    rotate=iaa.Affine(rotate=(-n, n))\n",
    "    rotated_image=rotate.augment_image(img)\n",
    "    return rotated_image\n",
    "\n",
    "def crop(img, n):\n",
    "    crop = iaa.Crop(percent=(n, n)) # crop image\n",
    "    crop_image=crop.augment_image(img)\n",
    "    return crop_image\n",
    "\n",
    "def sheer(img, n):\n",
    "    shear = iaa.Affine(shear=(-n,n))\n",
    "    shear_image=shear.augment_image(img)\n",
    "    return shear_image\n",
    "\n",
    "def hor_flip(img):\n",
    "    flip_hr=iaa.Fliplr(p=1.0)\n",
    "    flip_hr_image= flip_hr.augment_image(img)\n",
    "    return flip_hr_image\n",
    "\n",
    "def dilate(img, n):\n",
    "    kernel = np.ones((n,n),np.uint8)\n",
    "    dilated_image = cv2.dilate(trainxs[800],kernel,iterations = 1)\n",
    "    return dilate_image\n",
    "\n",
    "def trans(img, n):\n",
    "    num = random.randrange(int(n*-1),int(n))\n",
    "    move=iaa.Affine(translate_percent={\"x\": num/100}, scale=1)\n",
    "    trans_image = move.augment_image(img)\n",
    "    return trans_image\n",
    "\n",
    "trainxs = []\n",
    "trainximgs = []\n",
    "trainys = []\n",
    "\n",
    "DATADIR = \"/home/jupyter/MEng-Project/All Experiment Images/Toy 7 Point 1000\"\n",
    "\n",
    "CATEGORIES = [\"1_o\", \"2_o\", \"3_o\", \"4_o\",\"5_o\",\"6_o\", \"7_o\"]\n",
    "\n",
    "for x,category in enumerate(CATEGORIES):  \n",
    "    path = os.path.join(DATADIR,category)  \n",
    "    class_num = CATEGORIES.index(category)\n",
    "    #class_num = i[x]\n",
    "    print(class_num)\n",
    "    \n",
    "\n",
    "    for img in tqdm(os.listdir(path)):  # iterate over each image per point value\n",
    "        img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array \n",
    "        img_array = cv2.bitwise_not(img_array)\n",
    "        img_array = cv2.resize(img_array, (50,50))\n",
    "        trainys.append(class_num)\n",
    "        trainxs.append(img_array)\n",
    "    plt.imshow(img_array, cmap='gray')\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "\n",
    "trainxs1 = np.asarray(trainxs, dtype=np.float32)\n",
    "trainys1 = np.asarray(trainys, dtype=np.int)\n",
    "x_train1, x_test1, y_train_old1, y_test_old1 = train_test_split(trainxs1, trainys1, test_size=0.2, random_state=40)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,y in enumerate(x_train1):\n",
    "    \n",
    "    new_img_array1 = crop(x_train1[i], 0.1)\n",
    "    new_img_array1 = np.asarray(new_img_array1, dtype=np.float32)\n",
    "    x_train1 = np.vstack((x_train1,new_img_array1[None]))\n",
    "    y_train_old1 = np.append(y_train_old1, y_train_old1[i])\n",
    "    new_img_array2 = sheer(x_train1[i], 10)\n",
    "    new_img_array2 = np.asarray(new_img_array2, dtype=np.float32)\n",
    "    x_train1 = np.vstack((x_train1,new_img_array2[None]))\n",
    "    y_train_old1 = np.append(y_train_old1, y_train_old1[i])\n",
    "    new_img_array3 = trans(x_train1[i], 10)\n",
    "    new_img_array3 = np.asarray(new_img_array3, dtype=np.float32)\n",
    "    x_train1 = np.vstack((x_train1,new_img_array3[None]))\n",
    "    y_train_old1 = np.append(y_train_old1, y_train_old1[i])\n",
    "    new_img_array4 = rotation(x_train1[i], 10)\n",
    "    new_img_array4 = np.asarray(new_img_array4, dtype=np.float32)\n",
    "    x_train1 = np.vstack((x_train1,new_img_array4[None]))\n",
    "    y_train_old1 = np.append(y_train_old1, y_train_old1[i])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train1 = to_categorical(y_train_old1)\n",
    "y_test1 = to_categorical(y_test_old1)\n",
    "\n",
    "val = 0\n",
    "\n",
    "x_train = x_train1[:len(x_train1) - int(val*len(x_train1))]\n",
    "x_test = x_test1[:len(x_test1) - int(val*len(x_test1))]\n",
    "y_train = y_train1[:len(y_train1) - int(val*len(y_train1))]\n",
    "y_test = y_test1[:len(y_test1) - int(val*len(y_test1))]\n",
    "y_train_old = y_train_old1[:len(y_train_old1) - int(val*len(y_train_old1))]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#print(y_train_old)\n",
    "plt.rcParams.update({'figure.figsize':(7,5), 'figure.dpi':100})\n",
    "\n",
    "# Plot Histogram on x\n",
    "plt.hist(y_train_old, bins=20)\n",
    "plt.gca().set(title='Frequency Histogram', ylabel='Frequency');\n",
    "\n",
    "x_train.shape\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "#x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)\n",
    "\n",
    "#print(x_train[3])\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('y_train shape:', y_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Conv2D(356, (3, 3), activation='relu'))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(84, activation='relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "dim_img = img_rows * img_cols\n",
    "x_train = x_train.reshape(x_train.shape[0], dim_img)\n",
    "x_test = x_test.reshape(x_test.shape[0], dim_img)\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(dim_img,)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "#model.summary()\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainxs = []\n",
    "trainys = []\n",
    "\n",
    "DATADIR = r\"C:\\Users\\Tom\\Desktop\\All Experiment Images\\Toy 7 Point\"\n",
    "\n",
    "CATEGORIES = [\"1_o\", \"2_o\", \"3_o\", \"4_o\",\"5_o\",\"6_o\", \"7_o\"]\n",
    "\n",
    "\n",
    "for x,category in enumerate(CATEGORIES):  \n",
    "    path = os.path.join(DATADIR,category)  \n",
    "    class_num = CATEGORIES.index(category)\n",
    "    #class_num = i[x]\n",
    "    #print(class_num)\n",
    "    for img in os.listdir(path):  \n",
    "        img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n",
    "        img_array = cv2.bitwise_not(img_array)\n",
    "        img_array = cv2.resize(img_array, (100,100)).flatten()\n",
    "        trainys.append(class_num)\n",
    "        trainxs.append(img_array)\n",
    "        \n",
    "x_train, x_test, y_train_old, y_test_old = train_test_split(trainxs, trainys, test_size=0.2, random_state=42)\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)\n",
    "\n",
    "#print(x_train[3])\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "#import necessary modules\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "#print(x_train)\n",
    "#create object of the lassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=8)\n",
    "#Train the algorithm\n",
    "neigh.fit(x_train, y_train_old)\n",
    "# predict the response\n",
    "pred = neigh.predict(x_test)\n",
    "# evaluate accuracy\n",
    "print (\"KNeighbors accuracy score : \",accuracy_score(y_test_old, pred))\n",
    "\n",
    "# import the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "svm_model_linear = SVC(kernel = 'linear', C = 1).fit(x_train, y_train_old) \n",
    "svm_predictions = svm_model_linear.predict(x_test) \n",
    "\n",
    "  \n",
    "# creating a confusion matrix \n",
    "#cm = confusion_matrix(y_test_old, svm_predictions) \n",
    "print (\"svm accuracy score : \", svm_model_linear.score(x_test, y_test_old) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training a DescisionTreeClassifier \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "\n",
    "dtree_model = DecisionTreeClassifier(max_depth = 100).fit(x_train, y_train_old) \n",
    "\n",
    "pred = dtree_model.predict(x_test) \n",
    "\n",
    "print (\"Decision Tree accuracy score : \",accuracy_score(y_test_old, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1, max_features=10, max_depth=15, random_state=0)\n",
    "gb_clf.fit(x_train, y_train_old)\n",
    "pred = gb_clf.predict(x_test)\n",
    "# evaluate accuracy\n",
    "print (\"Gradient Boosted Classifier accuracy score : \",accuracy_score(y_test_old, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "cm=confusion_matrix(y_test_old,pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sn.heatmap(cm,annot=True,cmap='Blues', fmt='g')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
