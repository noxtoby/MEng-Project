{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "batch_size = 64\n",
    "num_classes = 1\n",
    "epochs = 5\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 70, 70\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:02<00:00, 342.21it/s]\n",
      "100%|██████████| 1000/1000 [00:02<00:00, 357.07it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.transform import rotate\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "\n",
    "trainxs = []\n",
    "trainximgs = []\n",
    "trainys = []\n",
    "\n",
    "DATADIR = r\"C:\\Users\\colly\\Desktop\\Toyimagesv3\"\n",
    "\n",
    "CATEGORIES = [\"out_square\", \"in_square\"]\n",
    "#CATEGORIES = [\"out_square\", \"in_square\", \"on_line\"]\n",
    "\n",
    "for category in CATEGORIES:\n",
    "    path = os.path.join(DATADIR,category) \n",
    "    class_num = CATEGORIES.index(category)\n",
    "    for img in os.listdir(path):  \n",
    "        img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n",
    "        plt.imshow(img_array, cmap='gray')  # graph it\n",
    "        plt.show()  # display!\n",
    "        print(class_num)\n",
    "          # we just want one for now so break\n",
    "        break\n",
    "\n",
    "\n",
    "for category in CATEGORIES:  \n",
    "\n",
    "    path = os.path.join(DATADIR,category)  \n",
    "    class_num = CATEGORIES.index(category)  # get the classification  (0 or a 1). 0=notinsquare 1=insquare\n",
    "\n",
    "    for img in tqdm(os.listdir(path)):  # iterate over each image per point value\n",
    "        img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array \n",
    "        new_img_array = rotate(img_array, 90)\n",
    "        new_img_array1 = rotate(img_array, 180)\n",
    "        new_img_array2 = rotate(img_array, 270)\n",
    "\n",
    "        trainys.append(class_num)\n",
    "        trainys.append(class_num)\n",
    "        trainys.append(class_num)\n",
    "        trainys.append(class_num)\n",
    "        trainxs.append(new_img_array)\n",
    "        trainxs.append(new_img_array1)\n",
    "        trainxs.append(new_img_array2)\n",
    "        trainxs.append(img_array)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6400, 70, 70)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "trainxs1 = np.asarray(trainxs, dtype=np.float32)\n",
    "trainys1 = np.asarray(trainys, dtype=np.float32)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(trainxs1, trainys1, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6400, 70, 70, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "#x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n",
      "x_train shape: (6400, 70, 70, 1)\n",
      "x_train shape: (6400, 70, 70, 1)\n",
      "6400 train samples\n",
      "1600 test samples\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 68, 68, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 66, 66, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 69696)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               8921216   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 8,940,161\n",
      "Trainable params: 8,940,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\"yes\")\n",
    "print('x_train shape:', x_train.shape)\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "#print(x_train[3])\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss=keras.losses.binary_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6400 samples, validate on 1600 samples\n",
      "Epoch 1/5\n",
      "6400/6400 [==============================] - ETA: 4:02 - loss: 0.6981 - accuracy: 0.43 - ETA: 3:07 - loss: 0.9902 - accuracy: 0.46 - ETA: 2:47 - loss: 1.0721 - accuracy: 0.45 - ETA: 2:36 - loss: 1.0125 - accuracy: 0.46 - ETA: 2:30 - loss: 0.9527 - accuracy: 0.47 - ETA: 2:26 - loss: 0.9107 - accuracy: 0.47 - ETA: 2:21 - loss: 0.8804 - accuracy: 0.47 - ETA: 2:18 - loss: 0.8571 - accuracy: 0.47 - ETA: 2:15 - loss: 0.8391 - accuracy: 0.47 - ETA: 2:12 - loss: 0.8243 - accuracy: 0.47 - ETA: 2:09 - loss: 0.8115 - accuracy: 0.49 - ETA: 2:06 - loss: 0.8020 - accuracy: 0.48 - ETA: 2:04 - loss: 0.7942 - accuracy: 0.48 - ETA: 2:02 - loss: 0.7872 - accuracy: 0.48 - ETA: 2:00 - loss: 0.7810 - accuracy: 0.48 - ETA: 1:58 - loss: 0.7756 - accuracy: 0.48 - ETA: 1:57 - loss: 0.7709 - accuracy: 0.48 - ETA: 1:55 - loss: 0.7665 - accuracy: 0.48 - ETA: 1:53 - loss: 0.7627 - accuracy: 0.48 - ETA: 1:52 - loss: 0.7592 - accuracy: 0.49 - ETA: 1:50 - loss: 0.7560 - accuracy: 0.49 - ETA: 1:48 - loss: 0.7531 - accuracy: 0.49 - ETA: 1:47 - loss: 0.7504 - accuracy: 0.49 - ETA: 1:45 - loss: 0.7480 - accuracy: 0.49 - ETA: 1:44 - loss: 0.7460 - accuracy: 0.49 - ETA: 1:42 - loss: 0.7438 - accuracy: 0.49 - ETA: 1:41 - loss: 0.7420 - accuracy: 0.49 - ETA: 1:39 - loss: 0.7404 - accuracy: 0.49 - ETA: 1:38 - loss: 0.7388 - accuracy: 0.49 - ETA: 1:36 - loss: 0.7372 - accuracy: 0.49 - ETA: 1:35 - loss: 0.7358 - accuracy: 0.49 - ETA: 1:34 - loss: 0.7344 - accuracy: 0.49 - ETA: 1:32 - loss: 0.7332 - accuracy: 0.49 - ETA: 1:31 - loss: 0.7320 - accuracy: 0.49 - ETA: 1:30 - loss: 0.7309 - accuracy: 0.49 - ETA: 1:28 - loss: 0.7298 - accuracy: 0.49 - ETA: 1:27 - loss: 0.7288 - accuracy: 0.49 - ETA: 1:25 - loss: 0.7279 - accuracy: 0.49 - ETA: 1:24 - loss: 0.7270 - accuracy: 0.49 - ETA: 1:23 - loss: 0.7262 - accuracy: 0.49 - ETA: 1:22 - loss: 0.7254 - accuracy: 0.49 - ETA: 1:21 - loss: 0.7246 - accuracy: 0.49 - ETA: 1:19 - loss: 0.7239 - accuracy: 0.49 - ETA: 1:18 - loss: 0.7232 - accuracy: 0.49 - ETA: 1:16 - loss: 0.7226 - accuracy: 0.49 - ETA: 1:15 - loss: 0.7219 - accuracy: 0.50 - ETA: 1:13 - loss: 0.7213 - accuracy: 0.50 - ETA: 1:12 - loss: 0.7207 - accuracy: 0.49 - ETA: 1:10 - loss: 0.7202 - accuracy: 0.50 - ETA: 1:09 - loss: 0.7196 - accuracy: 0.50 - ETA: 1:07 - loss: 0.7191 - accuracy: 0.50 - ETA: 1:06 - loss: 0.7186 - accuracy: 0.49 - ETA: 1:05 - loss: 0.7182 - accuracy: 0.49 - ETA: 1:03 - loss: 0.7177 - accuracy: 0.49 - ETA: 1:02 - loss: 0.7173 - accuracy: 0.49 - ETA: 1:00 - loss: 0.7169 - accuracy: 0.49 - ETA: 59s - loss: 0.7164 - accuracy: 0.5008 - ETA: 57s - loss: 0.7160 - accuracy: 0.501 - ETA: 56s - loss: 0.7156 - accuracy: 0.501 - ETA: 55s - loss: 0.7152 - accuracy: 0.503 - ETA: 53s - loss: 0.7149 - accuracy: 0.503 - ETA: 52s - loss: 0.7145 - accuracy: 0.504 - ETA: 50s - loss: 0.7142 - accuracy: 0.503 - ETA: 49s - loss: 0.7139 - accuracy: 0.502 - ETA: 48s - loss: 0.7136 - accuracy: 0.500 - ETA: 46s - loss: 0.7133 - accuracy: 0.500 - ETA: 45s - loss: 0.7130 - accuracy: 0.500 - ETA: 44s - loss: 0.7127 - accuracy: 0.499 - ETA: 42s - loss: 0.7124 - accuracy: 0.499 - ETA: 41s - loss: 0.7122 - accuracy: 0.499 - ETA: 40s - loss: 0.7119 - accuracy: 0.499 - ETA: 38s - loss: 0.7116 - accuracy: 0.499 - ETA: 37s - loss: 0.7114 - accuracy: 0.498 - ETA: 36s - loss: 0.7111 - accuracy: 0.498 - ETA: 34s - loss: 0.7109 - accuracy: 0.498 - ETA: 33s - loss: 0.7107 - accuracy: 0.497 - ETA: 32s - loss: 0.7105 - accuracy: 0.498 - ETA: 30s - loss: 0.7102 - accuracy: 0.498 - ETA: 29s - loss: 0.7100 - accuracy: 0.498 - ETA: 27s - loss: 0.7098 - accuracy: 0.499 - ETA: 26s - loss: 0.7096 - accuracy: 0.500 - ETA: 24s - loss: 0.7094 - accuracy: 0.500 - ETA: 23s - loss: 0.7092 - accuracy: 0.500 - ETA: 22s - loss: 0.7090 - accuracy: 0.500 - ETA: 20s - loss: 0.7088 - accuracy: 0.501 - ETA: 19s - loss: 0.7086 - accuracy: 0.501 - ETA: 18s - loss: 0.7084 - accuracy: 0.501 - ETA: 16s - loss: 0.7082 - accuracy: 0.501 - ETA: 15s - loss: 0.7080 - accuracy: 0.502 - ETA: 13s - loss: 0.7079 - accuracy: 0.501 - ETA: 12s - loss: 0.7078 - accuracy: 0.500 - ETA: 11s - loss: 0.7077 - accuracy: 0.500 - ETA: 9s - loss: 0.7075 - accuracy: 0.499 - ETA: 8s - loss: 0.7074 - accuracy: 0.49 - ETA: 6s - loss: 0.7072 - accuracy: 0.50 - ETA: 5s - loss: 0.7071 - accuracy: 0.50 - ETA: 4s - loss: 0.7069 - accuracy: 0.50 - ETA: 2s - loss: 0.7068 - accuracy: 0.50 - ETA: 1s - loss: 0.7067 - accuracy: 0.50 - 146s 23ms/step - loss: 0.7066 - accuracy: 0.4994 - val_loss: 0.6931 - val_accuracy: 0.5025\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400/6400 [==============================] - ETA: 2:21 - loss: 0.6936 - accuracy: 0.40 - ETA: 2:15 - loss: 0.6935 - accuracy: 0.44 - ETA: 2:14 - loss: 0.6931 - accuracy: 0.47 - ETA: 2:13 - loss: 0.6930 - accuracy: 0.48 - ETA: 2:10 - loss: 0.6931 - accuracy: 0.48 - ETA: 2:09 - loss: 0.6932 - accuracy: 0.48 - ETA: 2:08 - loss: 0.6931 - accuracy: 0.49 - ETA: 2:06 - loss: 0.6932 - accuracy: 0.49 - ETA: 2:04 - loss: 0.6932 - accuracy: 0.49 - ETA: 2:02 - loss: 0.6931 - accuracy: 0.49 - ETA: 2:00 - loss: 0.6931 - accuracy: 0.49 - ETA: 1:58 - loss: 0.6931 - accuracy: 0.50 - ETA: 1:57 - loss: 0.6932 - accuracy: 0.49 - ETA: 1:56 - loss: 0.6931 - accuracy: 0.49 - ETA: 1:55 - loss: 0.6931 - accuracy: 0.49 - ETA: 1:55 - loss: 0.6931 - accuracy: 0.50 - ETA: 1:55 - loss: 0.6932 - accuracy: 0.49 - ETA: 1:56 - loss: 0.6932 - accuracy: 0.49 - ETA: 1:56 - loss: 0.6932 - accuracy: 0.49 - ETA: 1:55 - loss: 0.6933 - accuracy: 0.49 - ETA: 1:54 - loss: 0.6933 - accuracy: 0.49 - ETA: 1:53 - loss: 0.6933 - accuracy: 0.49 - ETA: 1:52 - loss: 0.6933 - accuracy: 0.49 - ETA: 1:51 - loss: 0.6932 - accuracy: 0.49 - ETA: 1:51 - loss: 0.6933 - accuracy: 0.49 - ETA: 1:50 - loss: 0.6933 - accuracy: 0.49 - ETA: 1:49 - loss: 0.6933 - accuracy: 0.49 - ETA: 1:47 - loss: 0.6933 - accuracy: 0.49 - ETA: 1:46 - loss: 0.6933 - accuracy: 0.49 - ETA: 1:46 - loss: 0.6932 - accuracy: 0.49 - ETA: 1:47 - loss: 0.6932 - accuracy: 0.49 - ETA: 1:46 - loss: 0.6931 - accuracy: 0.50 - ETA: 1:45 - loss: 0.6932 - accuracy: 0.50 - ETA: 1:43 - loss: 0.6932 - accuracy: 0.50 - ETA: 1:42 - loss: 0.6932 - accuracy: 0.50 - ETA: 1:41 - loss: 0.6931 - accuracy: 0.50 - ETA: 1:40 - loss: 0.6931 - accuracy: 0.50 - ETA: 1:38 - loss: 0.6931 - accuracy: 0.50 - ETA: 1:37 - loss: 0.6932 - accuracy: 0.50 - ETA: 1:35 - loss: 0.6932 - accuracy: 0.50 - ETA: 1:33 - loss: 0.6932 - accuracy: 0.50 - ETA: 1:31 - loss: 0.6932 - accuracy: 0.50 - ETA: 1:30 - loss: 0.6932 - accuracy: 0.50 - ETA: 1:28 - loss: 0.6932 - accuracy: 0.50 - ETA: 1:27 - loss: 0.6932 - accuracy: 0.50 - ETA: 1:25 - loss: 0.6932 - accuracy: 0.50 - ETA: 1:24 - loss: 0.6932 - accuracy: 0.50 - ETA: 1:23 - loss: 0.6932 - accuracy: 0.50 - ETA: 1:21 - loss: 0.6932 - accuracy: 0.50 - ETA: 1:20 - loss: 0.6932 - accuracy: 0.50 - ETA: 1:18 - loss: 0.6931 - accuracy: 0.50 - ETA: 1:16 - loss: 0.6932 - accuracy: 0.50 - ETA: 1:16 - loss: 0.6932 - accuracy: 0.50 - ETA: 1:14 - loss: 0.6932 - accuracy: 0.50 - ETA: 1:13 - loss: 0.6932 - accuracy: 0.50 - ETA: 1:11 - loss: 0.6933 - accuracy: 0.50 - ETA: 1:10 - loss: 0.6933 - accuracy: 0.50 - ETA: 1:09 - loss: 0.6932 - accuracy: 0.50 - ETA: 1:08 - loss: 0.6932 - accuracy: 0.50 - ETA: 1:06 - loss: 0.6932 - accuracy: 0.50 - ETA: 1:04 - loss: 0.6932 - accuracy: 0.50 - ETA: 1:02 - loss: 0.6932 - accuracy: 0.50 - ETA: 1:01 - loss: 0.6932 - accuracy: 0.50 - ETA: 59s - loss: 0.6932 - accuracy: 0.5037 - ETA: 57s - loss: 0.6932 - accuracy: 0.503 - ETA: 55s - loss: 0.6932 - accuracy: 0.505 - ETA: 54s - loss: 0.6932 - accuracy: 0.504 - ETA: 52s - loss: 0.6932 - accuracy: 0.505 - ETA: 50s - loss: 0.6932 - accuracy: 0.506 - ETA: 48s - loss: 0.6932 - accuracy: 0.506 - ETA: 47s - loss: 0.6932 - accuracy: 0.505 - ETA: 45s - loss: 0.6932 - accuracy: 0.505 - ETA: 43s - loss: 0.6932 - accuracy: 0.506 - ETA: 42s - loss: 0.6932 - accuracy: 0.506 - ETA: 40s - loss: 0.6932 - accuracy: 0.504 - ETA: 38s - loss: 0.6932 - accuracy: 0.504 - ETA: 37s - loss: 0.6932 - accuracy: 0.504 - ETA: 35s - loss: 0.6932 - accuracy: 0.505 - ETA: 33s - loss: 0.6931 - accuracy: 0.506 - ETA: 32s - loss: 0.6931 - accuracy: 0.505 - ETA: 30s - loss: 0.6931 - accuracy: 0.503 - ETA: 28s - loss: 0.6932 - accuracy: 0.504 - ETA: 27s - loss: 0.6931 - accuracy: 0.502 - ETA: 25s - loss: 0.6932 - accuracy: 0.503 - ETA: 23s - loss: 0.6932 - accuracy: 0.502 - ETA: 22s - loss: 0.6932 - accuracy: 0.501 - ETA: 20s - loss: 0.6932 - accuracy: 0.501 - ETA: 19s - loss: 0.6932 - accuracy: 0.500 - ETA: 17s - loss: 0.6932 - accuracy: 0.501 - ETA: 16s - loss: 0.6932 - accuracy: 0.501 - ETA: 14s - loss: 0.6932 - accuracy: 0.501 - ETA: 13s - loss: 0.6932 - accuracy: 0.503 - ETA: 11s - loss: 0.6932 - accuracy: 0.505 - ETA: 9s - loss: 0.6932 - accuracy: 0.504 - ETA: 8s - loss: 0.6932 - accuracy: 0.50 - ETA: 6s - loss: 0.6932 - accuracy: 0.50 - ETA: 4s - loss: 0.6932 - accuracy: 0.50 - ETA: 3s - loss: 0.6932 - accuracy: 0.50 - ETA: 1s - loss: 0.6932 - accuracy: 0.50 - 179s 28ms/step - loss: 0.6932 - accuracy: 0.5041 - val_loss: 0.6928 - val_accuracy: 0.5025\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400/6400 [==============================] - ETA: 2:50 - loss: 0.6909 - accuracy: 0.50 - ETA: 2:48 - loss: 0.6891 - accuracy: 0.53 - ETA: 2:49 - loss: 0.6949 - accuracy: 0.52 - ETA: 2:46 - loss: 0.6951 - accuracy: 0.50 - ETA: 2:38 - loss: 0.6944 - accuracy: 0.52 - ETA: 2:34 - loss: 0.6944 - accuracy: 0.50 - ETA: 2:29 - loss: 0.6940 - accuracy: 0.50 - ETA: 2:26 - loss: 0.6943 - accuracy: 0.49 - ETA: 2:22 - loss: 0.6942 - accuracy: 0.49 - ETA: 2:24 - loss: 0.6941 - accuracy: 0.49 - ETA: 2:23 - loss: 0.6940 - accuracy: 0.49 - ETA: 2:22 - loss: 0.6938 - accuracy: 0.50 - ETA: 2:20 - loss: 0.6940 - accuracy: 0.49 - ETA: 2:18 - loss: 0.6940 - accuracy: 0.49 - ETA: 2:16 - loss: 0.6939 - accuracy: 0.49 - ETA: 2:13 - loss: 0.6938 - accuracy: 0.50 - ETA: 2:10 - loss: 0.6937 - accuracy: 0.50 - ETA: 2:08 - loss: 0.6936 - accuracy: 0.50 - ETA: 2:05 - loss: 0.6936 - accuracy: 0.50 - ETA: 2:03 - loss: 0.6936 - accuracy: 0.50 - ETA: 2:01 - loss: 0.6937 - accuracy: 0.50 - ETA: 1:59 - loss: 0.6938 - accuracy: 0.50 - ETA: 1:57 - loss: 0.6937 - accuracy: 0.50 - ETA: 1:56 - loss: 0.6936 - accuracy: 0.50 - ETA: 1:55 - loss: 0.6935 - accuracy: 0.50 - ETA: 1:53 - loss: 0.6933 - accuracy: 0.50 - ETA: 1:51 - loss: 0.6952 - accuracy: 0.50 - ETA: 1:50 - loss: 0.6951 - accuracy: 0.50 - ETA: 1:49 - loss: 0.6950 - accuracy: 0.51 - ETA: 1:48 - loss: 0.6949 - accuracy: 0.51 - ETA: 1:47 - loss: 0.6948 - accuracy: 0.51 - ETA: 1:46 - loss: 0.6948 - accuracy: 0.51 - ETA: 1:45 - loss: 0.6948 - accuracy: 0.51 - ETA: 1:44 - loss: 0.6947 - accuracy: 0.51 - ETA: 1:42 - loss: 0.6947 - accuracy: 0.50 - ETA: 1:40 - loss: 0.6947 - accuracy: 0.50 - ETA: 1:38 - loss: 0.6947 - accuracy: 0.50 - ETA: 1:36 - loss: 0.6947 - accuracy: 0.50 - ETA: 1:35 - loss: 0.6946 - accuracy: 0.50 - ETA: 1:33 - loss: 0.6946 - accuracy: 0.50 - ETA: 1:31 - loss: 0.6946 - accuracy: 0.50 - ETA: 1:29 - loss: 0.6945 - accuracy: 0.50 - ETA: 1:28 - loss: 0.6945 - accuracy: 0.50 - ETA: 1:26 - loss: 0.6944 - accuracy: 0.50 - ETA: 1:24 - loss: 0.6944 - accuracy: 0.50 - ETA: 1:23 - loss: 0.6944 - accuracy: 0.50 - ETA: 1:21 - loss: 0.6943 - accuracy: 0.50 - ETA: 1:19 - loss: 0.6943 - accuracy: 0.50 - ETA: 1:17 - loss: 0.6943 - accuracy: 0.50 - ETA: 1:16 - loss: 0.6943 - accuracy: 0.49 - ETA: 1:14 - loss: 0.6943 - accuracy: 0.49 - ETA: 1:12 - loss: 0.6943 - accuracy: 0.49 - ETA: 1:11 - loss: 0.6943 - accuracy: 0.49 - ETA: 1:09 - loss: 0.6942 - accuracy: 0.49 - ETA: 1:08 - loss: 0.6942 - accuracy: 0.49 - ETA: 1:06 - loss: 0.6942 - accuracy: 0.49 - ETA: 1:05 - loss: 0.6942 - accuracy: 0.49 - ETA: 1:04 - loss: 0.6941 - accuracy: 0.49 - ETA: 1:02 - loss: 0.6941 - accuracy: 0.49 - ETA: 1:01 - loss: 0.6941 - accuracy: 0.49 - ETA: 59s - loss: 0.6941 - accuracy: 0.4974 - ETA: 57s - loss: 0.6941 - accuracy: 0.497 - ETA: 56s - loss: 0.6940 - accuracy: 0.497 - ETA: 54s - loss: 0.6940 - accuracy: 0.497 - ETA: 53s - loss: 0.6940 - accuracy: 0.496 - ETA: 51s - loss: 0.6940 - accuracy: 0.495 - ETA: 50s - loss: 0.6941 - accuracy: 0.494 - ETA: 48s - loss: 0.6940 - accuracy: 0.496 - ETA: 47s - loss: 0.6940 - accuracy: 0.494 - ETA: 45s - loss: 0.6940 - accuracy: 0.496 - ETA: 43s - loss: 0.6940 - accuracy: 0.495 - ETA: 42s - loss: 0.6939 - accuracy: 0.496 - ETA: 40s - loss: 0.6939 - accuracy: 0.496 - ETA: 39s - loss: 0.6939 - accuracy: 0.496 - ETA: 37s - loss: 0.6939 - accuracy: 0.498 - ETA: 36s - loss: 0.6939 - accuracy: 0.497 - ETA: 34s - loss: 0.6939 - accuracy: 0.497 - ETA: 33s - loss: 0.6938 - accuracy: 0.498 - ETA: 31s - loss: 0.6939 - accuracy: 0.499 - ETA: 30s - loss: 0.6938 - accuracy: 0.498 - ETA: 28s - loss: 0.6939 - accuracy: 0.498 - ETA: 27s - loss: 0.6938 - accuracy: 0.498 - ETA: 25s - loss: 0.6938 - accuracy: 0.499 - ETA: 24s - loss: 0.6937 - accuracy: 0.500 - ETA: 22s - loss: 0.6939 - accuracy: 0.500 - ETA: 21s - loss: 0.6939 - accuracy: 0.499 - ETA: 19s - loss: 0.6939 - accuracy: 0.500 - ETA: 18s - loss: 0.6939 - accuracy: 0.500 - ETA: 16s - loss: 0.6938 - accuracy: 0.501 - ETA: 15s - loss: 0.6938 - accuracy: 0.502 - ETA: 13s - loss: 0.6938 - accuracy: 0.503 - ETA: 12s - loss: 0.6937 - accuracy: 0.504 - ETA: 10s - loss: 0.6937 - accuracy: 0.504 - ETA: 9s - loss: 0.6937 - accuracy: 0.504 - ETA: 7s - loss: 0.6937 - accuracy: 0.50 - ETA: 6s - loss: 0.6938 - accuracy: 0.50 - ETA: 4s - loss: 0.6938 - accuracy: 0.50 - ETA: 3s - loss: 0.6937 - accuracy: 0.50 - ETA: 1s - loss: 0.6938 - accuracy: 0.50 - 163s 25ms/step - loss: 0.6938 - accuracy: 0.5045 - val_loss: 0.6916 - val_accuracy: 0.5300\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400/6400 [==============================] - ETA: 3:15 - loss: 0.6912 - accuracy: 0.51 - ETA: 3:41 - loss: 0.6895 - accuracy: 0.55 - ETA: 3:25 - loss: 0.6888 - accuracy: 0.53 - ETA: 3:12 - loss: 0.6871 - accuracy: 0.53 - ETA: 2:59 - loss: 0.6916 - accuracy: 0.53 - ETA: 3:00 - loss: 0.6924 - accuracy: 0.52 - ETA: 3:09 - loss: 0.6916 - accuracy: 0.53 - ETA: 3:09 - loss: 0.6913 - accuracy: 0.53 - ETA: 3:14 - loss: 0.6920 - accuracy: 0.53 - ETA: 3:16 - loss: 0.6923 - accuracy: 0.52 - ETA: 3:13 - loss: 0.6921 - accuracy: 0.52 - ETA: 3:08 - loss: 0.6916 - accuracy: 0.52 - ETA: 3:03 - loss: 0.6912 - accuracy: 0.52 - ETA: 2:58 - loss: 0.6931 - accuracy: 0.52 - ETA: 2:55 - loss: 0.6931 - accuracy: 0.51 - ETA: 2:54 - loss: 0.6931 - accuracy: 0.50 - ETA: 2:55 - loss: 0.6934 - accuracy: 0.50 - ETA: 3:02 - loss: 0.6935 - accuracy: 0.50 - ETA: 3:00 - loss: 0.6933 - accuracy: 0.50 - ETA: 3:01 - loss: 0.6931 - accuracy: 0.50 - ETA: 3:00 - loss: 0.6928 - accuracy: 0.51 - ETA: 2:57 - loss: 0.6929 - accuracy: 0.51 - ETA: 2:55 - loss: 0.6927 - accuracy: 0.51 - ETA: 2:53 - loss: 0.6930 - accuracy: 0.50 - ETA: 2:50 - loss: 0.6931 - accuracy: 0.50 - ETA: 2:47 - loss: 0.6929 - accuracy: 0.51 - ETA: 2:44 - loss: 0.6929 - accuracy: 0.51 - ETA: 2:43 - loss: 0.6927 - accuracy: 0.51 - ETA: 2:40 - loss: 0.6926 - accuracy: 0.51 - ETA: 2:38 - loss: 0.6934 - accuracy: 0.51 - ETA: 2:35 - loss: 0.6932 - accuracy: 0.51 - ETA: 2:32 - loss: 0.6931 - accuracy: 0.51 - ETA: 2:28 - loss: 0.6931 - accuracy: 0.51 - ETA: 2:26 - loss: 0.6930 - accuracy: 0.51 - ETA: 2:22 - loss: 0.6930 - accuracy: 0.51 - ETA: 2:18 - loss: 0.6930 - accuracy: 0.51 - ETA: 2:16 - loss: 0.6930 - accuracy: 0.51 - ETA: 2:14 - loss: 0.6932 - accuracy: 0.50 - ETA: 2:12 - loss: 0.6932 - accuracy: 0.50 - ETA: 2:10 - loss: 0.6931 - accuracy: 0.50 - ETA: 2:08 - loss: 0.6931 - accuracy: 0.50 - ETA: 2:05 - loss: 0.6931 - accuracy: 0.50 - ETA: 2:02 - loss: 0.6930 - accuracy: 0.50 - ETA: 1:59 - loss: 0.6930 - accuracy: 0.50 - ETA: 1:57 - loss: 0.6930 - accuracy: 0.51 - ETA: 1:54 - loss: 0.6928 - accuracy: 0.51 - ETA: 1:52 - loss: 0.6927 - accuracy: 0.51 - ETA: 1:51 - loss: 0.6926 - accuracy: 0.51 - ETA: 1:48 - loss: 0.6926 - accuracy: 0.51 - ETA: 1:46 - loss: 0.6931 - accuracy: 0.51 - ETA: 1:43 - loss: 0.6930 - accuracy: 0.51 - ETA: 1:41 - loss: 0.6929 - accuracy: 0.51 - ETA: 1:38 - loss: 0.6928 - accuracy: 0.51 - ETA: 1:36 - loss: 0.6931 - accuracy: 0.51 - ETA: 1:33 - loss: 0.6931 - accuracy: 0.51 - ETA: 1:31 - loss: 0.6930 - accuracy: 0.51 - ETA: 1:28 - loss: 0.6929 - accuracy: 0.51 - ETA: 1:26 - loss: 0.6928 - accuracy: 0.51 - ETA: 1:23 - loss: 0.6928 - accuracy: 0.51 - ETA: 1:21 - loss: 0.6929 - accuracy: 0.51 - ETA: 1:19 - loss: 0.6927 - accuracy: 0.51 - ETA: 1:17 - loss: 0.6927 - accuracy: 0.51 - ETA: 1:14 - loss: 0.6926 - accuracy: 0.51 - ETA: 1:12 - loss: 0.6926 - accuracy: 0.51 - ETA: 1:10 - loss: 0.6925 - accuracy: 0.51 - ETA: 1:08 - loss: 0.6927 - accuracy: 0.51 - ETA: 1:06 - loss: 0.6926 - accuracy: 0.51 - ETA: 1:04 - loss: 0.6927 - accuracy: 0.51 - ETA: 1:01 - loss: 0.6926 - accuracy: 0.51 - ETA: 59s - loss: 0.6925 - accuracy: 0.5147 - ETA: 57s - loss: 0.6925 - accuracy: 0.514 - ETA: 55s - loss: 0.6926 - accuracy: 0.514 - ETA: 52s - loss: 0.6924 - accuracy: 0.515 - ETA: 50s - loss: 0.6926 - accuracy: 0.513 - ETA: 48s - loss: 0.6926 - accuracy: 0.513 - ETA: 46s - loss: 0.6926 - accuracy: 0.512 - ETA: 44s - loss: 0.6926 - accuracy: 0.513 - ETA: 42s - loss: 0.6925 - accuracy: 0.513 - ETA: 40s - loss: 0.6924 - accuracy: 0.514 - ETA: 38s - loss: 0.6924 - accuracy: 0.514 - ETA: 36s - loss: 0.6924 - accuracy: 0.514 - ETA: 34s - loss: 0.6924 - accuracy: 0.513 - ETA: 32s - loss: 0.6922 - accuracy: 0.515 - ETA: 30s - loss: 0.6921 - accuracy: 0.516 - ETA: 28s - loss: 0.6920 - accuracy: 0.516 - ETA: 26s - loss: 0.6919 - accuracy: 0.517 - ETA: 25s - loss: 0.6920 - accuracy: 0.516 - ETA: 23s - loss: 0.6920 - accuracy: 0.516 - ETA: 21s - loss: 0.6920 - accuracy: 0.515 - ETA: 19s - loss: 0.6920 - accuracy: 0.515 - ETA: 17s - loss: 0.6920 - accuracy: 0.516 - ETA: 15s - loss: 0.6919 - accuracy: 0.517 - ETA: 13s - loss: 0.6918 - accuracy: 0.517 - ETA: 11s - loss: 0.6918 - accuracy: 0.516 - ETA: 9s - loss: 0.6919 - accuracy: 0.516 - ETA: 7s - loss: 0.6918 - accuracy: 0.51 - ETA: 5s - loss: 0.6918 - accuracy: 0.51 - ETA: 3s - loss: 0.6917 - accuracy: 0.51 - ETA: 1s - loss: 0.6916 - accuracy: 0.51 - 206s 32ms/step - loss: 0.6916 - accuracy: 0.5172 - val_loss: 0.6842 - val_accuracy: 0.5250\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400/6400 [==============================] - ETA: 3:11 - loss: 0.6751 - accuracy: 0.57 - ETA: 2:46 - loss: 0.7354 - accuracy: 0.54 - ETA: 2:38 - loss: 0.7175 - accuracy: 0.54 - ETA: 2:32 - loss: 0.7116 - accuracy: 0.51 - ETA: 2:28 - loss: 0.7080 - accuracy: 0.50 - ETA: 2:24 - loss: 0.7021 - accuracy: 0.52 - ETA: 2:22 - loss: 0.6993 - accuracy: 0.53 - ETA: 2:23 - loss: 0.6977 - accuracy: 0.53 - ETA: 2:24 - loss: 0.6967 - accuracy: 0.52 - ETA: 2:26 - loss: 0.6968 - accuracy: 0.52 - ETA: 2:23 - loss: 0.6959 - accuracy: 0.51 - ETA: 2:20 - loss: 0.6943 - accuracy: 0.52 - ETA: 2:19 - loss: 0.6937 - accuracy: 0.52 - ETA: 2:17 - loss: 0.6930 - accuracy: 0.51 - ETA: 2:15 - loss: 0.6931 - accuracy: 0.51 - ETA: 2:13 - loss: 0.6924 - accuracy: 0.52 - ETA: 2:10 - loss: 0.6922 - accuracy: 0.52 - ETA: 2:08 - loss: 0.6918 - accuracy: 0.51 - ETA: 2:05 - loss: 0.6908 - accuracy: 0.51 - ETA: 2:03 - loss: 0.6909 - accuracy: 0.51 - ETA: 2:01 - loss: 0.6903 - accuracy: 0.51 - ETA: 1:59 - loss: 0.6896 - accuracy: 0.51 - ETA: 1:57 - loss: 0.6891 - accuracy: 0.51 - ETA: 1:55 - loss: 0.6883 - accuracy: 0.51 - ETA: 1:54 - loss: 0.6884 - accuracy: 0.51 - ETA: 1:52 - loss: 0.6886 - accuracy: 0.51 - ETA: 1:50 - loss: 0.6886 - accuracy: 0.51 - ETA: 1:48 - loss: 0.6882 - accuracy: 0.51 - ETA: 1:46 - loss: 0.6881 - accuracy: 0.51 - ETA: 1:45 - loss: 0.6885 - accuracy: 0.51 - ETA: 1:44 - loss: 0.6888 - accuracy: 0.51 - ETA: 1:42 - loss: 0.6886 - accuracy: 0.51 - ETA: 1:40 - loss: 0.6879 - accuracy: 0.52 - ETA: 1:39 - loss: 0.6872 - accuracy: 0.52 - ETA: 1:37 - loss: 0.6869 - accuracy: 0.52 - ETA: 1:35 - loss: 0.6866 - accuracy: 0.52 - ETA: 1:34 - loss: 0.6860 - accuracy: 0.52 - ETA: 1:32 - loss: 0.6851 - accuracy: 0.53 - ETA: 1:30 - loss: 0.6849 - accuracy: 0.53 - ETA: 1:29 - loss: 0.6849 - accuracy: 0.53 - ETA: 1:28 - loss: 0.6854 - accuracy: 0.52 - ETA: 1:26 - loss: 0.6855 - accuracy: 0.52 - ETA: 1:25 - loss: 0.6857 - accuracy: 0.52 - ETA: 1:24 - loss: 0.6860 - accuracy: 0.52 - ETA: 1:22 - loss: 0.6855 - accuracy: 0.52 - ETA: 1:21 - loss: 0.6869 - accuracy: 0.52 - ETA: 1:19 - loss: 0.6871 - accuracy: 0.52 - ETA: 1:18 - loss: 0.6870 - accuracy: 0.52 - ETA: 1:16 - loss: 0.6873 - accuracy: 0.52 - ETA: 1:15 - loss: 0.6870 - accuracy: 0.52 - ETA: 1:13 - loss: 0.6866 - accuracy: 0.52 - ETA: 1:11 - loss: 0.6864 - accuracy: 0.52 - ETA: 1:10 - loss: 0.6864 - accuracy: 0.52 - ETA: 1:08 - loss: 0.6864 - accuracy: 0.52 - ETA: 1:07 - loss: 0.6862 - accuracy: 0.52 - ETA: 1:05 - loss: 0.6859 - accuracy: 0.52 - ETA: 1:04 - loss: 0.6856 - accuracy: 0.52 - ETA: 1:02 - loss: 0.6853 - accuracy: 0.52 - ETA: 1:01 - loss: 0.6849 - accuracy: 0.52 - ETA: 59s - loss: 0.6861 - accuracy: 0.5260 - ETA: 57s - loss: 0.6865 - accuracy: 0.525 - ETA: 56s - loss: 0.6867 - accuracy: 0.525 - ETA: 54s - loss: 0.6867 - accuracy: 0.525 - ETA: 53s - loss: 0.6863 - accuracy: 0.525 - ETA: 52s - loss: 0.6860 - accuracy: 0.526 - ETA: 50s - loss: 0.6863 - accuracy: 0.526 - ETA: 49s - loss: 0.6862 - accuracy: 0.525 - ETA: 47s - loss: 0.6861 - accuracy: 0.526 - ETA: 46s - loss: 0.6864 - accuracy: 0.526 - ETA: 44s - loss: 0.6862 - accuracy: 0.527 - ETA: 43s - loss: 0.6862 - accuracy: 0.527 - ETA: 41s - loss: 0.6860 - accuracy: 0.527 - ETA: 40s - loss: 0.6860 - accuracy: 0.528 - ETA: 38s - loss: 0.6858 - accuracy: 0.528 - ETA: 37s - loss: 0.6857 - accuracy: 0.528 - ETA: 35s - loss: 0.6856 - accuracy: 0.531 - ETA: 34s - loss: 0.6857 - accuracy: 0.530 - ETA: 32s - loss: 0.6858 - accuracy: 0.531 - ETA: 31s - loss: 0.6857 - accuracy: 0.531 - ETA: 29s - loss: 0.6853 - accuracy: 0.532 - ETA: 28s - loss: 0.6851 - accuracy: 0.532 - ETA: 26s - loss: 0.6852 - accuracy: 0.531 - ETA: 25s - loss: 0.6850 - accuracy: 0.532 - ETA: 23s - loss: 0.6851 - accuracy: 0.531 - ETA: 22s - loss: 0.6852 - accuracy: 0.531 - ETA: 20s - loss: 0.6851 - accuracy: 0.531 - ETA: 19s - loss: 0.6850 - accuracy: 0.531 - ETA: 17s - loss: 0.6851 - accuracy: 0.532 - ETA: 16s - loss: 0.6849 - accuracy: 0.532 - ETA: 14s - loss: 0.6847 - accuracy: 0.531 - ETA: 13s - loss: 0.6845 - accuracy: 0.531 - ETA: 11s - loss: 0.6846 - accuracy: 0.532 - ETA: 10s - loss: 0.6844 - accuracy: 0.532 - ETA: 8s - loss: 0.6846 - accuracy: 0.532 - ETA: 7s - loss: 0.6849 - accuracy: 0.53 - ETA: 5s - loss: 0.6846 - accuracy: 0.53 - ETA: 4s - loss: 0.6845 - accuracy: 0.53 - ETA: 2s - loss: 0.6843 - accuracy: 0.53 - ETA: 1s - loss: 0.6841 - accuracy: 0.53 - 155s 24ms/step - loss: 0.6839 - accuracy: 0.5341 - val_loss: 0.6675 - val_accuracy: 0.5587\n",
      "Test loss: 0.6675487291812897\n",
      "Test accuracy: 0.5587499737739563\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
